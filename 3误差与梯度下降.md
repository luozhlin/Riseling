# ä¸‰ã€åå·®ä¸æ¢¯åº¦ä¸‹é™

## Bias and Variance

ä¸€ä¸ªæ¨¡å‹çš„è¯¯å·®ä¸»è¦æ¥æºäºä¸¤éƒ¨åˆ†ï¼šbias and variance

* **bias**: ä¼°è®¡å€¼ä¸çœŸå®å€¼ä¹‹é—´å­˜åœ¨çš„å·®å¼‚
* **Variance**: æè¿°æ•°æ®ä¹‹é—´çš„ç¦»æ•£ç¨‹åº¦ï¼Œå³æ³¢åŠ¨èŒƒå›´

åœ¨å®é™…æƒ…å†µä¸­ï¼Œæˆ‘ä»¬æ˜¯é€šè¿‡æ ·æœ¬æ¥è¿›è¡Œæ¨æ–­ï¼Œæ‰€ä»¥å¾—åˆ°çš„ç»“æœéƒ½æ˜¯ä¼°è®¡å€¼ï¼Œä¸€èˆ¬ä¼šä½¿ç”¨$\hat y$çš„æ–¹å¼æ¥è¡¨ç¤ºã€‚å…³äºbiaså’Œvarianceè§ä¸‹é¢ä¾‹å­

è®¾å˜é‡$X$çš„è§‚æµ‹å€¼ä¸º$x_1,x_2,\cdots,x_n$, ä¸”çœŸå®çš„å‡å€¼ï¼ˆæœŸæœ›ï¼‰ä¸º$\mu$ï¼Œæ–¹å·®ä¸º$\sigma^2$ï¼Œä½†æ˜¯éƒ½æœªçŸ¥

ç°é€šè¿‡è§‚æµ‹å€¼æ¥ä¼°è®¡å‡å€¼å’Œæ–¹å·®
$$
\hat \mu = \frac{1}{n}\sum_{i=1}^n x_i \neq \mu \\
{\rm Var}(\hat \mu)=\frac{\sigma^2}{n}
$$
å¯ä»¥çœ‹å‡º$\hat \mu$ä¼šæ ¹æ®æ ·æœ¬çš„ä¸åŒè€Œå˜åŒ–ï¼Œå¿…å®šä¼šä¸çœŸå®å­˜åœ¨å·®å¼‚ï¼Œä»è€Œå¯¼è‡´biasï¼›è€Œå…¶æ–¹å·®åˆ™ä¸$n$æœ‰å…³ï¼Œ$n$è¶Šå¤§ï¼Œæ–¹å·®è¶Šå°ï¼Œç»“æœå°±è¶Šç²¾ç¡®
$$
s^2=\frac{1}{n}\sum_{i=1}^n(x_i-\hat \mu)^2\\
E[s^2]=\frac{n-1}{n}\sigma^2 \neq \sigma^2 
$$
$s^2$çš„æœŸæœ›å¹¶ä¸ç­‰äºçœŸå®çš„æ€»ä½“æ–¹å·®ï¼Œæˆ‘ä»¬ç§°è¿™ç§ä¼°è®¡å«åšæœ‰åä¼°è®¡(Biased estimator)ï¼Œç›¸åº”çš„ï¼Œä¹Ÿå­˜åœ¨æ— åä¼°è®¡(Unbiased estimator)

ä¸‹å›¾ä¸ºbiaså’Œvarianceçš„å½¢è±¡å±•ç¤º

![image-20210917151445383](C:\Users\luozl\AppData\Roaming\Typora\typora-user-images\image-20210917151445383.png)

è¶Šç®€å•çš„æ¨¡å‹ï¼Œå—æ ·æœ¬æ•°æ®çš„å½±å“è¶Šå°ï¼Œæ–¹å·®å°±è¶Šå°

#### Solve large bias

* è¾“å…¥æ›´å¤šfeatures
* ä½¿ç”¨æ›´å¤æ‚çš„æ¨¡å‹

#### Solve large variance

* ä½¿ç”¨æ›´å¤šæ•°æ®ï¼Œä½†ä¸ä¸€å®šæ€»æ˜¯èµ·ä½œç”¨
* æ­£åˆ™åŒ–ï¼Œé€šè¿‡æ­£åˆ™åŒ–ï¼Œå¯ä»¥æ˜¯æ‹Ÿåˆæ›´åŠ å¹³æ»‘ï¼Œé¿å…è¿‡å¤§çš„æ³¢åŠ¨

### Model Selection

é€šå¸¸æƒ…å†µä¸‹ï¼ŒBiasè¶Šå¤§ï¼ŒVarianceè¶Šå°(underfitting)ï¼›Biasè¶Šå°ï¼ŒVarianceè¶Šå¤§(overfitting)ï¼Œæ‰€ä»¥éœ€è¦æ ¹æ®å®é™…æƒ…å†µé€‰æ‹©åˆé€‚çš„æ¨¡å‹ï¼Œå°†Biaså’ŒVarianceæ§åˆ¶åœ¨åˆç†èŒƒå›´ä¹‹å†…

ä»¥ä¸‹æ˜¯å‡ ç§å¸¸ç”¨çš„æ–¹æ³•

#### Cross Validation(äº¤å‰éªŒè¯)

![image-20210917153709320](C:\Users\luozl\AppData\Roaming\Typora\typora-user-images\image-20210917153709320.png)

å°†è®­ç»ƒé›†åˆ†æˆæµ‹è¯•é›†å’ŒéªŒè¯é›†ï¼Œå½“ä¸¤éƒ¨åˆ†çš„è¯¯å·®éƒ½è¾ƒå°ï¼Œåˆ™å¯ä»¥é€‰æ‹©è¯¥æ¨¡å‹

#### N-fold Cross Validation

![image-20210917153827844](C:\Users\luozl\AppData\Roaming\Typora\typora-user-images\image-20210917153827844.png)

å°†æ•°æ®é›†éšæœºå¹³å‡åˆ†æˆ$N$ä»½ï¼Œæ¯æ¬¡å°†å…¶ä¸­$1$ä»½ä½œä¸ºéªŒè¯é›†ï¼Œå¦å¤–çš„$N-1$ä»½ä½œä¸ºè®­ç»ƒé›†ï¼Œä¸€å…±è¿›è¡Œ$N$æ¬¡ï¼Œè®¡ç®—è¿™$N$æ¬¡éªŒè¯é›†è¯¯å·®çš„å¹³å‡å€¼ï¼Œå¹³å‡è¯¯å·®è¶Šå°ï¼Œåˆ™æ¨¡å‹æ•ˆæœè¶Šå¥½

## Gradient Descent

å›é¡¾ä¸Šä¸€ç« å†…å®¹ï¼Œæ¢¯åº¦ä¸‹é™æ³•æ˜¯è§£å†³å¦‚ä¸‹ä¼˜åŒ–é—®é¢˜
$$
\theta^*={\rm arg \ min }L(\theta)
$$
å…¶ä¸­$L$ä¸ºloss function, $\theta$ä¸ºæ±‚è§£å‚æ•°

è§£æ³•å¦‚ä¸‹

![image-20210917155308534](C:\Users\luozl\AppData\Roaming\Typora\typora-user-images\image-20210917155308534.png)

å…¶ä¸­$\eta$ç§°ä¸ºlearning rate, æ˜¯äººä¸ºè°ƒæ•´çš„

<img src="C:\Users\luozl\AppData\Roaming\Typora\typora-user-images\image-20210917155912675.png" alt="image-20210917155912675" style="zoom:50%;" />

å³ä¸ºGradientï¼Œæ˜¯Lossçš„ç­‰é«˜çº¿çš„æ³•çº¿æ–¹å‘ï¼Œå¦‚å›¾ç¤º

![image-20210917160044197](C:\Users\luozl\AppData\Roaming\Typora\typora-user-images\image-20210917160044197.png)

ç›´åˆ°ç»“æœå‚æ•°å˜åŒ–å¾ˆå°ï¼Œå³æ”¶æ•›åˆ°ä¸€å®šèŒƒå›´å†…åœæ­¢ï¼Œæ¥ä¸‹æ¥å†å¯¹æ¢¯åº¦ä¸‹é™è¿›è¡Œæ›´è¯¦ç»†çš„è®²è§£

### Tip 1: Tuning your learning rates

$\eta$çš„è®¾ç½®å¿…é¡»ä»”ç»†è€ƒè™‘ï¼Œè¿™ä¼šå†³å®šä¸‹é™çš„é€Ÿç‡ï¼Œä¼šå½±å“è®¡ç®—æœºè®¡ç®—çš„æ—¶é—´ä»¥åŠç»“æœæ­£ç¡®æ€§ã€‚è®¾ç½®è¿‡å¤§ï¼Œå¯èƒ½ä¼šé”™è¿‡å±€éƒ¨æœ€ä¼˜å€¼ï¼Œè®¾ç½®è¿‡å°ï¼Œåˆå¯èƒ½è®¡ç®—æ—¶é—´è¿‡é•¿

![image-20210917160512052](C:\Users\luozl\AppData\Roaming\Typora\typora-user-images\image-20210917160512052.png)

å¦‚å›¾ä¸­é»„çº¿ä¸º$\eta$è®¾ç½®è¿‡å¤§ï¼Œé”™è¿‡äº†å±€éƒ¨æœ€ä¼˜å€¼ï¼›ç»¿çº¿åŒç†ï¼Œä¸”å¯¼è‡´äº†æ— æ³•æ±‚è§£ï¼›è“çº¿è®¾ç½®è¿‡å°ï¼Œè®¡ç®—é‡è¾ƒå¤§

æ³¨æ„ï¼šå·¦å›¾åªæœ‰1ç»´å’Œ2ç»´æƒ…å†µæ‰èƒ½å¯è§†åŒ–ï¼Œæ‰€ä»¥ä¸€èˆ¬é‡‡ç”¨å³å›¾çš„æ–¹å¼

#### Adaptive Learning Rates

* æ™®éä¸”ç®€å•çš„æƒ³æ³•: åœ¨æ¯ä¸€æ­¥é€šè¿‡æŸäº›å› ç´ å‡å°learning rate
  * å¼€å§‹æ—¶ï¼Œæˆ‘ä»¬ç¦»ç›®æ ‡å€¼è¾ƒè¿œï¼Œå¯ä»¥ä½¿ç”¨è¾ƒå¤§çš„learning rate
  * åœ¨è¿­ä»£å‡ æ¬¡åï¼Œç¦»ç›®æ ‡æ¸è¿‘ï¼Œæ‰€ä»¥å‡å°learning rate
  * E.g. $1/t$ decay: $ğœ‚^ğ‘¡ = ğœ‚/\sqrt{ğ‘¡ + 1}$
* Learning rate ä¸å¯èƒ½å§‹ç»ˆå¦‚ä¸€
  * ä¸åŒçš„parametersä½¿ç”¨ä¸åŒçš„learning rates  

##### Adagrad

å…³å¥ï¼šä¸åŒçš„å‚æ•°$\eta$ä¼šä¸åŒ

##### ![image-20210917163656574](C:\Users\luozl\AppData\Roaming\Typora\typora-user-images\image-20210917163656574.png)

* $\sigma$æ˜¯å‰tæ¬¡å¯¹$w$æ±‚å¾®åˆ†çš„å¹³æ–¹å’Œçš„å‡å€¼å¼€æ ¹å·ï¼Œæ‰€ä»¥ä¸åŒå‚æ•°çš„$\eta$ä¼šä¸åŒ

![image-20210917163712195](C:\Users\luozl\AppData\Roaming\Typora\typora-user-images\image-20210917163712195.png)

* Divide the learning rate of each parameter by the root mean square of its previous derivatives  

![image-20210917163758813](C:\Users\luozl\AppData\Roaming\Typora\typora-user-images\image-20210917163758813.png)

#### Contradiction

![image-20210917184857147](C:\Users\luozl\AppData\Roaming\Typora\typora-user-images\image-20210917184857147.png)

* ç›´è§‚è§£é‡Šï¼šåˆ†æ¯è¿™ä¸€é¡¹ï¼Œå°±æ˜¯ç”¨æ¥è¯„ä¼°è¿™ä¸ªåå·®çš„æ•ˆæœ

![image-20210917185318538](C:\Users\luozl\AppData\Roaming\Typora\typora-user-images\image-20210917185318538.png)

* 1ä¸ªå‚æ•°æ—¶ï¼Œæ¢¯åº¦è¶Šå¤§ï¼Œç¦»æœ€ä½ç‚¹è·ç¦»è¶Šè¿œï¼Œä¸‹å›¾ä»¥äºŒæ¬¡å‡½æ•°ä¸ºä¾‹

![image-20210917185731762](C:\Users\luozl\AppData\Roaming\Typora\typora-user-images\image-20210917185731762.png)

* å¤šä¸ªå‚æ•°æ—¶ï¼Œä¸Šè¿°ç»“è®ºä¸æˆç«‹

![image-20210917185852668](C:\Users\luozl\AppData\Roaming\Typora\typora-user-images\image-20210917185852668.png)

* best stepï¼šæ‰¿æ¥äºŒæ¬¡å‡½æ•°çš„ä¾‹å­ï¼Œè·ç¦»ä¸ä»…ä¸ä¸€æ¬¡å¾®åˆ†å‘ˆæ­£æ¯”ï¼Œè¿˜ä¸äºŒæ¬¡å¾®åˆ†å‘ˆåæ¯”ã€‚è¿™æ ·æ‰èƒ½çœŸæ­£æ˜¾ç¤ºæœ€å¥½çš„è·ç¦»

![image-20210917190020793](C:\Users\luozl\AppData\Roaming\Typora\typora-user-images\image-20210917190020793.png)

* å› æ­¤ï¼ŒAdagradå°±ç±»ä¼¼äºä¸Šè¿°å…³ç³»ï¼Œåˆ†æ¯å…¶å®å°±æ˜¯ä¼°è®¡äºŒæ¬¡å¾®åˆ†

![image-20210917190615104](C:\Users\luozl\AppData\Roaming\Typora\typora-user-images\image-20210917190615104.png)

### Tip 2: Stochastic Gradient Descent

åŸç†ï¼šæ¯æ¬¡éšæœºå–1ä¸ªæ ·æœ¬$x_n$ï¼Œè®¡ç®—å…¶Lossï¼Œè®°ä¸º$L^n$ï¼Œç„¶åå°±æ›´æ–°ä¸€æ¬¡å‚æ•°

![image-20210917190921334](C:\Users\luozl\AppData\Roaming\Typora\typora-user-images\image-20210917190921334.png)

* å·¦å›¾ä¸ºä¸€èˆ¬æ–¹æ³•ï¼Œè·¯å¾„æ¯”è¾ƒç¨³å®š
* å³å›¾åˆ™ä¸ºéšæœºæ–¹æ³•ï¼Œæ›´æ–°ä¼šæ›´å¿«

### Tip 3: Feature Scaling

å‡è®¾åšå¦‚ä¸‹å›å½’

![image-20210917164626363](C:\Users\luozl\AppData\Roaming\Typora\typora-user-images\image-20210917164626363.png)

å½“featureçš„åº¦é‡ä¸ä¸€è‡´æ—¶ï¼Œä¸åŒfeatureæ•°æ®å·®å¼‚æ˜¯ä¸ä¸€è‡´çš„ï¼Œè‹¥ç›´æ¥ä½¿ç”¨æ¢¯åº¦ä¸‹é™ï¼Œä¼šå¯¼è‡´å¦‚å·¦å›¾çš„ç»“æœâ€”â€”åªåœ¨å‡ ä¹ä¸€ä¸ªæ–¹å‘ä¸Šä¸‹é™ï¼Œè‹¥æ ‡å‡†åŒ–åï¼Œåˆ™å¦‚å³å›¾ï¼Œæ›´æ˜“æ‰¾åˆ°åˆé€‚çš„ä¸‹é™

#### å¤„ç†æ–¹æ³•

![image-20210917164852495](C:\Users\luozl\AppData\Roaming\Typora\typora-user-images\image-20210917164852495.png)

è¿™æ ·ï¼Œæ ‡å‡†åŒ–åï¼Œå„ä¸ªfeatureçš„å‡å€¼ä¸º0ï¼Œæ–¹å·®éƒ½ä¸º1ï¼Œåº¦é‡åˆ™ç»Ÿä¸€äº†

### ç†è®ºæ¨å¯¼

* **NOTE**

**Question**ï¼šæ¯æ¬¡æ›´æ–°æ˜¯Lossæ›´å°ï¼Œåˆ™è¿™ä¸ªå‚æ•°æ­£ç¡®å—ï¼Ÿ

**Answer**ï¼šä¸ä¸€å®šï¼Œæœ¬å°±å¯èƒ½ä¸‹é™

* **Formal** **Derivation**

![image-20210917191632681](C:\Users\luozl\AppData\Roaming\Typora\typora-user-images\image-20210917191632681.png)

ç°åœ¨é—®é¢˜æ˜¯ï¼Œå¦‚ä½•åœ¨æŒ‡å®šç‚¹é™„è¿‘ï¼Œå¯»æ‰¾åˆ°æœ€å°å€¼ï¼Ÿ

* å‰æï¼š**Taylor Series**

å¯ä»¥å°†ä»»æ„å‡½æ•°è¿›è¡Œæ³°å‹’å±•å¼€ï¼Œå¦‚$h(x)$å¯ä»¥å†™æˆ

![image-20210917191742647](C:\Users\luozl\AppData\Roaming\Typora\typora-user-images\image-20210917191742647.png)

å¤šå…ƒå‡½æ•°åŒæ ·å¯ä»¥æ³°å‹’å±•å¼€ï¼Œå¦‚$h(x,y)$å¯ä»¥å†™æˆ

![image-20210917191903385](C:\Users\luozl\AppData\Roaming\Typora\typora-user-images\image-20210917191903385.png)

* è®¾Loss functionä¸º$L(\theta)$

![image-20210917192217570](C:\Users\luozl\AppData\Roaming\Typora\typora-user-images\image-20210917192217570.png)

![image-20210917192245012](C:\Users\luozl\AppData\Roaming\Typora\typora-user-images\image-20210917192245012.png)

![image-20210917192423426](C:\Users\luozl\AppData\Roaming\Typora\typora-user-images\image-20210917192423426.png)

å¯¹äºä¸Šå›¾2å…ƒçš„æƒ…å†µï¼Œå®é™…ä¸Šå°±æ˜¯åœ¨å®šä¹‰åœ†å†…æ‰¾åˆ°ä½¿$L(\theta)$æœ€å°çš„ç‚¹ï¼Œä¸”$L(\theta)$æ˜¯ä¸€æ¡ç›´çº¿ï¼Œåªè¦ä½¿å¾—$\Delta \theta_1$ä¸$\Delta \theta_2$ï¼Œä¸ç›´çº¿ç³»æ•°$u,v$ç›¸åï¼Œä¸”æ‰¾åˆ°æœ€è¿œçš„ç‚¹å³å¯

çº¢è‰²åœ†åœˆåŠå¾„è¶Šå°ï¼Œå¼å­è¶Šæˆç«‹ï¼Œæ‰€ä»¥éœ€è¦learning rateè¶³å¤Ÿå°ï¼Œä½†å®é™…ä¸Šä¹Ÿä¸èƒ½å¤ªå°

å¦‚æœè€ƒè™‘åˆ°äºŒæ¬¡å¼ï¼ˆç‰›é¡¿æ³•ï¼‰ï¼Œåˆ™learning rateå¯ç¨å¾®å¤§äº›ï¼Œä½†æ˜¯ä¼šæ˜æ˜¾å¢åŠ è¿ç®—é‡

### å±€é™

æ¢¯åº¦ä¸‹é™å¯èƒ½ä¼šåœ¨å¦‚ä¸‹ä½ç½®åœæ­¢

* å±€éƒ¨æœ€å°å€¼çš„ä½ç½®
* å¾®åˆ†ä¸ºæˆ–è¿‘ä¼¼0çš„åœ°æ–¹

![image-20210917193422778](C:\Users\luozl\AppData\Roaming\Typora\typora-user-images\image-20210917193422778.png)

